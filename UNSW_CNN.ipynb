{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZEmlR_A8Gy30"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle \n",
    "from os import path\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QE9BV5QvbtmO"
   },
   "source": [
    "# **Importing Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e6PZCWoDG9uO"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'UNSW_NB15_training-set.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\A  Project Related To CN (28.10.23)\\UNSW_CNN.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/A%20%20Project%20Related%20To%20CN%20%2828.10.23%29/UNSW_CNN.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mUNSW_NB15_training-set.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/A%20%20Project%20Related%20To%20CN%20%2828.10.23%29/UNSW_CNN.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mUNSW_NB15_testing-set.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/A%20%20Project%20Related%20To%20CN%20%2828.10.23%29/UNSW_CNN.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([train, test], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32me:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32me:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32me:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[1;32me:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32me:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'UNSW_NB15_training-set.csv'"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
    "test = pd.read_csv(\"UNSW_NB15_testing-set.csv\")\n",
    "data = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySdfpAsaCabg"
   },
   "outputs": [],
   "source": [
    "data['service'].replace('-',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots( figsize=(40, 20))\n",
    "sns.histplot(data[data['label'] == 1]['service'], color='green')\n",
    "sns.histplot(data[data['label'] ==0]['service'], color='yellow')\n",
    "axes.tick_params('x', labelrotation=45,width=6,labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zO7VNaGKDYDA",
    "outputId": "71d063d1-13b0-4391-cd12-5551e170c907"
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIPIPT0PD1b_"
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJNxMEoqbYvG",
    "outputId": "7bb21df1-c32f-4b17-f86e-fc7165b7c980"
   },
   "outputs": [],
   "source": [
    "data['attack_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rFnIMHYxcYWW",
    "outputId": "b24711a9-6d26-468b-e724-169a758fb489"
   },
   "outputs": [],
   "source": [
    "data['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGfimWMVFKmr"
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"NUSW-NB15_features.csv\",encoding='cp1252')\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "hrYdxinYvMP9",
    "outputId": "d0e10f0f-42f2-4edc-deee-a2fde81679cd"
   },
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jT53NXCYfQDX"
   },
   "outputs": [],
   "source": [
    "features['Type '] = features['Type '].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UifBmzfc7Mx"
   },
   "outputs": [],
   "source": [
    "nominal_names = features['Name'][features['Type ']=='nominal']\n",
    "integer_names = features['Name'][features['Type ']=='integer']\n",
    "binary_names = features['Name'][features['Type ']=='binary']\n",
    "float_names = features['Name'][features['Type ']=='float']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Sc2ttPn6r7Tz"
   },
   "outputs": [],
   "source": [
    "cols = data.columns\n",
    "nominal_names = cols.intersection(nominal_names)\n",
    "integer_names = cols.intersection(integer_names)\n",
    "binary_names = cols.intersection(binary_names)\n",
    "float_names = cols.intersection(float_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "f-z_BVLyu0vE"
   },
   "outputs": [],
   "source": [
    "for c in integer_names:\n",
    "  pd.to_numeric(data[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hc_tnXdGvkpD"
   },
   "outputs": [],
   "source": [
    "for c in binary_names:\n",
    "  pd.to_numeric(data[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "M3uJUVe9vpyx"
   },
   "outputs": [],
   "source": [
    "for c in float_names:\n",
    "  pd.to_numeric(data[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHfR566WrIr6",
    "outputId": "31a815e5-ef87-4748-c01a-0a2fe3bd85af"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "iDzUyKPRm4x3",
    "outputId": "605c803b-b14a-471a-f795-d2196d82a585"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.pie(data.label.value_counts(),labels=['normal','abnormal'],autopct='%0.2f%%')\n",
    "plt.title(\"Pie chart distribution of normal and abnormal labels\",fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "6hX-4d1dncqJ",
    "outputId": "8b260eb7-e34a-449f-8e4c-617bd59640e3"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.pie(data.attack_cat.value_counts(),labels=data.attack_cat.unique(),autopct='%0.2f%%')\n",
    "plt.title('Pie chart distribution of multi-class labels')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZX0Je4EM5ta",
    "outputId": "fe11efcd-32e2-47dd-8a7c-529688e28712"
   },
   "outputs": [],
   "source": [
    "num_col = data.select_dtypes(include='number').columns\n",
    "cat_col = data.columns.difference(num_col)\n",
    "cat_col = cat_col[1:]\n",
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "DxnGrVa1Odma",
    "outputId": "59215629-bfda-424e-925a-5cc49a2402b4"
   },
   "outputs": [],
   "source": [
    "data_cat = data[cat_col].copy()\n",
    "data_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6cnwo01NHP_"
   },
   "outputs": [],
   "source": [
    "data_cat = pd.get_dummies(data_cat,columns=cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oO6juQh4NQxL"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data, data_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C0nK7HFmNe8w"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=cat_col,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7G3s0etHwGUc",
    "outputId": "441e591d-d436-4a5f-ef71-21f4a92d03b9"
   },
   "outputs": [],
   "source": [
    "num_col = list(data.select_dtypes(include='number').columns)\n",
    "num_col.remove('id')\n",
    "num_col.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-phVbE8yal8w"
   },
   "outputs": [],
   "source": [
    "minmax_scale = MinMaxScaler(feature_range=(0, 1))\n",
    "def normalization(df,col):\n",
    "  for i in col:\n",
    "    arr = df[i]\n",
    "    arr = np.array(arr)\n",
    "    df[i] = minmax_scale.fit_transform(arr.reshape(len(arr),1))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "GyC-geCscBTR",
    "outputId": "4fa93447-ddf5-4431-9f11-35468442b2c8"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQq5bTuscFrU"
   },
   "outputs": [],
   "source": [
    "data = normalization(data.copy(),num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "jxaw2yKYcN9X",
    "outputId": "c6f0d252-e9c1-4254-c3f4-9873b483af21"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGSplI_VjHR0"
   },
   "outputs": [],
   "source": [
    "bin_label = pd.DataFrame(data.label.map(lambda x:'normal' if x==0 else 'abnormal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYJbRZ5oimGg"
   },
   "outputs": [],
   "source": [
    "bin_data = data.copy()\n",
    "bin_data['label'] = bin_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UvUkBqtjagH"
   },
   "outputs": [],
   "source": [
    "le1 = preprocessing.LabelEncoder()\n",
    "enc_label = bin_label.apply(le1.fit_transform)\n",
    "bin_data['label'] = enc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIe07KITjg--",
    "outputId": "b6a289a1-be51-4855-9e13-0d639bc4e8e8"
   },
   "outputs": [],
   "source": [
    "le1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wq-XBOn7tvXl"
   },
   "outputs": [],
   "source": [
    "np.save(\"le1_classes.npy\",le1.classes_,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WHf2Hk5i1Tr"
   },
   "outputs": [],
   "source": [
    "multi_data = data.copy()\n",
    "multi_label = pd.DataFrame(multi_data.attack_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDI2osuxCVRt"
   },
   "outputs": [],
   "source": [
    "multi_data = pd.get_dummies(multi_data,columns=['attack_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tuv1nDFj-z7"
   },
   "outputs": [],
   "source": [
    "le2 = preprocessing.LabelEncoder()\n",
    "enc_label = multi_label.apply(le2.fit_transform)\n",
    "multi_data['label'] = enc_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASjsFfv-kK7T",
    "outputId": "f0b07a49-996e-4a08-d4f1-fed72fa91019"
   },
   "outputs": [],
   "source": [
    "le2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKoH6sN8typc"
   },
   "outputs": [],
   "source": [
    "np.save(\"le2_classes.npy\",le2.classes_,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJIPk62ZiFpM"
   },
   "outputs": [],
   "source": [
    "num_col.append('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "h1tV8-lTcQSF",
    "outputId": "5d1af2ca-2943-4b97-ec0f-f1bc40232331"
   },
   "outputs": [],
   "source": [
    "# Correlation Matrix for Binary Labels\n",
    "plt.figure(figsize=(20,8))\n",
    "corr_bin = bin_data[num_col].corr()\n",
    "sns.heatmap(corr_bin,vmax=1.0,annot=False)\n",
    "plt.title('Correlation Matrix for Binary Labels',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCq2FNRbDGVJ"
   },
   "outputs": [],
   "source": [
    "num_col = list(multi_data.select_dtypes(include='number').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "GGobKJQTktZW",
    "outputId": "0e76cd3b-ab5f-4c53-afff-171293a2b9ed"
   },
   "outputs": [],
   "source": [
    "# Correlation Matrix for Multi-class Labels\n",
    "plt.figure(figsize=(20,8))\n",
    "corr_multi = multi_data[num_col].corr()\n",
    "sns.heatmap(corr_multi,vmax=1.0,annot=False)\n",
    "plt.title('Correlation Matrix for Multi Labels',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l4=data[['attack_cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_encoder4 =   LabelEncoder()\n",
    "l4_= lb_encoder4.fit_transform(l4)\n",
    "\n",
    "data[\"attack_cat\"]=l4_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_feature_detect(data, threshold=0.98):\n",
    "    quasi_constant_feature = []\n",
    "    for feature in data.columns:\n",
    "        predominant = (data[feature].value_counts() / float(\n",
    "                      len(data))).sort_values(ascending=False).values[0]\n",
    "        if predominant >= threshold:\n",
    "            quasi_constant_feature.append(feature)\n",
    "    print(len(quasi_constant_feature), ' variables are found to be almost constant')    \n",
    "    return quasi_constant_feature\n",
    "\n",
    "# the original dataset has no constant variable\n",
    "quasi_constant_feature = constant_feature_detect(data=data, threshold=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(quasi_constant_feature,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X         = data.iloc[:,:-3]\n",
    "Y         = np.array(data.iloc[:,-3])\n",
    "Y         = Y.reshape(len(Y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set aside 20% of the data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, shuffle=True, random_state=43)\n",
    "\n",
    "# Further split the training data into 80% for training and 20% for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "distances_train, indices_train = knn.kneighbors(X_train_scaled)\n",
    "distances_test, indices_test = knn.kneighbors(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = np.concatenate([X_train_scaled, distances_train], axis=1)\n",
    "X_test_combined = np.concatenate([X_test_scaled, distances_test], axis=1)\n",
    "\n",
    "# Reshape data for CNN-LSTM input\n",
    "X_train_combined_reshaped = X_train_combined.reshape(X_train_combined.shape[0], X_train_combined.shape[1], 1)\n",
    "X_test_combined_reshaped = X_test_combined.reshape(X_test_combined.shape[0], X_test_combined.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combined = Sequential()\n",
    "model_combined.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_combined_reshaped.shape[1], 1)))\n",
    "model_combined.add(MaxPooling1D(pool_size=3))\n",
    "model_combined.add(LSTM(units=40, activation='relu', return_sequences=True))\n",
    "model_combined.add(Dropout(0.1))\n",
    "model_combined.add(LSTM(units=20, activation='relu'))\n",
    "model_combined.add(Dropout(0.05))\n",
    "model_combined.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combined.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "model_combined.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "callbacks_combined = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "                     ModelCheckpoint(filepath='best_model_combined', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history_combined = model_combined.fit(X_train_combined_reshaped, y_train, epochs=100,\n",
    "                                      validation_data=(X_val, y_val),\n",
    "                                      batch_size=500,\n",
    "                                      callbacks=callbacks_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_vs_validation(history, model):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    \n",
    "    # Accuracy Plot\n",
    "    ax[0].plot(history.history['accuracy'], 'b-', label=\"Training Accuracy\")\n",
    "    ax[0].plot(history.history['val_accuracy'], 'r-', label=\"Validation Accuracy\")\n",
    "    ax[0].set_title('Training vs Validation Accuracy - ' + model)\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].grid(True)\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Loss Plot\n",
    "    ax[1].plot(history.history['loss'], 'g-', label=\"Training Loss\")\n",
    "    ax[1].plot(history.history['val_loss'], 'c-', label=\"Validation Loss\")\n",
    "    ax[1].set_title('Training vs Validation Loss - ' + model)\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].grid(True)\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_vs_validation(history_combined,\"ADAM-LSTM\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of iotml.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
